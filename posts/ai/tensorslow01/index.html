<!doctype html><html lang=zh-CN><head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#"><meta charset=UTF-8><meta name=generator content="Hugo 0.135.0"><meta name=theme-color content="#fff"><meta name=color-scheme content="light dark"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=format-detection content="telephone=no, date=no, address=no, email=no"><meta http-equiv=Cache-Control content="no-transform"><meta http-equiv=Cache-Control content="no-siteapp"><title>有趣的TensorSlow(上) | Misty</title>
<link rel=stylesheet href=/css/meme.min.css><script src=https://cdn.jsdelivr.net/npm/instantsearch.js@2/dist/instantsearch.min.js defer></script><script src=/js/meme.min.js></script><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Noto+Serif+SC:wght@400;500;700&amp;family=Source+Code+Pro:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" media=print onload='this.media="all"'><noscript><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Noto+Serif+SC:wght@400;500;700&amp;family=Source+Code+Pro:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap"></noscript><meta name=author content="Yajun"><meta name=description content="TensorFlow的许多概念，如graph, session, operation等，为什么要这么设计？Github上的TensorSlow用纯python来模仿了TF的底层api，加深理解TF中的底层概念。"><link rel="shortcut icon" href=/favicon.ico type=image/x-icon><link rel=mask-icon href=/icons/safari-pinned-tab.svg color=#2a6df4><link rel=apple-touch-icon sizes=180x180 href=/icons/apple-touch-icon.png><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-title content="Misty"><meta name=apple-mobile-web-app-status-bar-style content="black"><meta name=mobile-web-app-capable content="yes"><meta name=application-name content="Misty"><meta name=msapplication-starturl content="../../../"><meta name=msapplication-TileColor content="#fff"><meta name=msapplication-TileImage content="../../../icons/mstile-150x150.png"><link rel=manifest href=/manifest.json><link rel=canonical href=https://yinyajun.github.io/posts/ai/tensorslow01/><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","datePublished":"2019-06-01T22:37:36+00:00","dateModified":"2023-10-24T19:28:42+08:00","url":"https://yinyajun.github.io/posts/ai/tensorslow01/","headline":"有趣的TensorSlow(上)","description":"TensorFlow的许多概念，如graph, session, operation等，为什么要这么设计？Github上的TensorSlow用纯python来模仿了TF的底层api，加深理解TF中的底层概念。","inLanguage":"zh-CN","articleSection":"posts","wordCount":2306,"image":["https://pic.downk.cc/item/5e4d3a8248b86553eeaa37eb.png","https://pic.downk.cc/item/5e4d3a8248b86553eeaa37ed.png"],"author":{"@type":"Person","description":"凡是过往，结尾序章","email":"skyblueice234@gmail.com","image":"https://yinyajun.github.io/icons/apple-touch-icon.png","url":"https://yinyajun.github.io/","name":"Yajun"},"publisher":{"@type":"Organization","name":"Misty","logo":{"@type":"ImageObject","url":"https://yinyajun.github.io/icons/apple-touch-icon.png"},"url":"https://yinyajun.github.io/"},"mainEntityOfPage":{"@type":"WebSite","@id":"https://yinyajun.github.io/"}}</script><meta name=twitter:card content="summary_large_image"><meta property="og:title" content="有趣的TensorSlow(上)"><meta property="og:description" content="TensorFlow的许多概念，如graph, session, operation等，为什么要这么设计？Github上的TensorSlow用纯python来模仿了TF的底层api，加深理解TF中的底层概念。"><meta property="og:url" content="https://yinyajun.github.io/posts/ai/tensorslow01/"><meta property="og:site_name" content="Misty"><meta property="og:locale" content="zh"><meta property="og:image" content="https://pic.downk.cc/item/5e4d3a8248b86553eeaa37eb.png"><meta property="og:type" content="article"><meta property="article:published_time" content="2019-06-01T22:37:36+00:00"><meta property="article:modified_time" content="2023-10-24T19:28:42+08:00"><meta property="article:section" content="posts"></head><body><div class=container><header class=header><div class=header-wrapper><div class="header-inner single"><div class=site-brand><a href=/ class=brand>Misty</a></div><nav class=nav><ul class=menu id=menu><li class=menu-item><a href=/categories/><span class=menu-item-name>分类</span></a></li><li class=menu-item><a href=/archives/><span class=menu-item-name>归档</span></a></li><li class=menu-item><a href=/tags/><span class=menu-item-name>标签</span></a></li><li class=menu-item><a href=/about/><span class=menu-item-name>关于</span></a></li><li class=menu-item><a id=theme-switcher href=#><svg viewBox="0 0 512 512" class="icon theme-icon-light"><path d="M193.2 104.5 242 7a18 18 0 0128 0l48.8 97.5L422.2 70A18 18 0 01442 89.8l-34.5 103.4L505 242a18 18 0 010 28l-97.5 48.8L442 422.2A18 18 0 01422.2 442l-103.4-34.5L270 505a18 18 0 01-28 0l-48.8-97.5L89.8 442A18 18 0 0170 422.2l34.5-103.4-97.5-48.8a18 18 0 010-28l97.5-48.8L70 89.8A18 18 0 0189.8 70zM256 128a128 128 0 10.01.0M256 160a96 96 0 10.01.0"/></svg><svg viewBox="0 0 512 512" class="icon theme-icon-dark"><path d="M27 412A256 256 0 10181 5a11.5 11.5.0 00-5 20A201.5 201.5.0 0142 399a11.5 11.5.0 00-15 13"/></svg></a></li><li class="menu-item search-item"><form id=search class=search role=search><label for=search-input><svg viewBox="0 0 512 512" class="icon search-icon"><path d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></label>
<input type=search id=search-input class=search-input></form><template id=search-result hidden><article class="content post"><h2 class=post-title><a class=summary-title-link></a></h2><summary class=summary></summary><div class=read-more-container><a class=read-more-link>阅读更多 »</a></div></article></template></li></ul></nav></div></div></header><main class="main single" id=main><div class=main-inner><article class="content post h-entry" data-align=justify data-type=posts data-toc-num=true><h1 class="post-title p-name">有趣的TensorSlow(上)</h1><div class=post-meta><time datetime=2019-06-01T22:37:36+00:00 class="post-meta-item published dt-published"><svg viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M148 288h-40c-6.6.0-12-5.4-12-12v-40c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v40c0 6.6-5.4 12-12 12zm108-12v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm-96 96v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm-96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm192 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm96-260v352c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h48V12c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v52h128V12c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v52h48c26.5.0 48 21.5 48 48zm-48 346V160H48v298c0 3.3 2.7 6 6 6h340c3.3.0 6-2.7 6-6z"/></svg>&nbsp;2019/6/1</time></div><div class="post-body e-content"><p style=text-indent:0><span class=drop-cap>T</span>ensorFlow的许多概念，如graph, session, operation等，为什么要这么设计？Github上的TensorSlow用纯python来模仿了TF的底层api，加深理解TF中的底层概念。</p><h2 id=tensorslow简介><a href=#tensorslow简介 class=anchor-link><svg viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96.0-59.27-59.26-59.27-155.7.0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757.0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037.0 01-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482.0 0120.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96.0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454.0 0020.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037.0 00-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639.0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>TensorSlow简介</h2><ul><li>极简的模仿TensorFlow的API的python包。</li><li>使用纯python作为后端。</li><li>仅用作教学目的，帮助理解TensorFlow底层原理。</li><li>代码量非常少，跟着教程走，很容易看完。</li></ul><blockquote><p>本文是对原作者danielsabinasz的<a href=http://www.deepideas.net/deep-learning-from-scratch-theory-and-implementation/ target=_blank rel=noopener>教程</a>
的基础上，添加了一点自己的理解。</p><p>TensorSlow <a href=https://github.com/danielsabinasz/TensorSlow target=_blank rel=noopener><strong>Github repo地址</strong></a>
TensorSlow原作者<a href=http://www.deepideas.net/deep-learning-from-scratch-theory-and-implementation/ target=_blank rel=noopener><strong>英文教程</strong></a></p><p><em>The source code has been built with maximal understandability in mind, rather than maximal efficiency.</em></p></blockquote><h2 id=计算图computational-graphs><a href=#计算图computational-graphs class=anchor-link><svg viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96.0-59.27-59.26-59.27-155.7.0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757.0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037.0 01-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482.0 0120.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96.0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454.0 0020.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037.0 00-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639.0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>计算图Computational Graphs</h2><p>计算图是一种有向图，它是以图的形式来表示或计算数学函数。和普通的图一样，计算图中也有节点和边。</p><ul><li><strong>节点</strong>：要么是提供输入数据的节点，要么是代表操作数据的函数的节点。</li><li><strong>边</strong>：函数参数（或者说数据依赖），以流的形式为节点传输数据。</li><li><strong>Tensor</strong>: 节点的输入和输出数据，其实就是一个多维的array。</li></ul><p>下图展示了一个计算图，它描述了怎么计算输入节点$x$和$y$的和$z$的过程。</p><p><img src=https://pic.downk.cc/item/5e4d3a8248b86553eeaa37eb.png alt=计算图></p><p>$x$和$y$都是$z$的输入节点，而$z$是$x$和$y$的消费节点。节点$z$描述了这么一个方程：</p><p>$$z:\mathcal{R}^2 \rightarrow \mathcal{R}, z(x,y) = x + y.$$</p><p>计算图这个概念非常有用，特别当计算非常复杂的时候，下面的例子对应于一个仿射变换:
$$z(A,x,b)= Ax+b$$</p><p><img src=https://pic.downk.cc/item/5e4d3a8248b86553eeaa37ed.png alt=仿射变换的计算图></p><p>首先了解各类型节点的表示，从节点输入，节点输出和节点操作来考察各类型节点。</p><h3 id=operations节点><a href=#operations节点 class=anchor-link><svg viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96.0-59.27-59.26-59.27-155.7.0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757.0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037.0 01-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482.0 0120.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96.0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454.0 0020.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037.0 00-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639.0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Operations节点</h3><p>每个operation节点以下面三个表征：</p><ul><li><strong>节点操作</strong>：当operation节点的输入的值给定时，用<code>compute</code>函数来计算该operation节点的输出</li><li><strong>节点输入</strong>：<code>input_nodes</code>列表，可以是varibles节点或者是其他operations节点</li><li><strong>节点输出</strong>：<code>consumers</code>列表，它们将该operation节点的输出作为它们的输入。</li></ul><p>上面三个含义都是显而易见的描述operation节点的操作，在<code>Opearation</code>类中，用三个成员表示</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Operation</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_nodes</span><span class=o>=</span><span class=p>[]):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>input_nodes</span> <span class=o>=</span> <span class=n>input_nodes</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Initialize list of consumers </span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>consumers</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Append this operation to the list of consumers of all input nodes</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>input_node</span> <span class=ow>in</span> <span class=n>input_nodes</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>input_node</span><span class=o>.</span><span class=n>consumers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Append this operation to the list of operations in the currently active default graph</span>
</span></span><span class=line><span class=cl>        <span class=n>_default_graph</span><span class=o>.</span><span class=n>operations</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>compute</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>pass</span>
</span></span></code></pre></td></tr></table></div></div></div><p><code>compute</code>方法是需要每个operation节点子类去实现。</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Addition Operation节点示例</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>add</span><span class=p>(</span><span class=n>Operation</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Returns x + y element-wise.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>([</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>compute</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x_value</span><span class=p>,</span> <span class=n>y_value</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>inputs</span> <span class=o>=</span> <span class=p>[</span><span class=n>x_value</span><span class=p>,</span> <span class=n>y_value</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x_value</span> <span class=o>+</span> <span class=n>y_value</span>
</span></span></code></pre></td></tr></table></div></div></div><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Matrix Multiplicaiton Operation节点示例</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>matmul</span><span class=p>(</span><span class=n>Operation</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Multiplies matrix a by matrix b, producing a * b.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>([</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>compute</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>a_value</span><span class=p>,</span> <span class=n>b_value</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>inputs</span> <span class=o>=</span> <span class=p>[</span><span class=n>a_value</span><span class=p>,</span> <span class=n>b_value</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>a_value</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>b_value</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></div><h3 id=placeholder节点><a href=#placeholder节点 class=anchor-link><svg viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96.0-59.27-59.26-59.27-155.7.0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757.0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037.0 01-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482.0 0120.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96.0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454.0 0020.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037.0 00-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639.0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Placeholder节点</h3><p>计算图中为了计算输出，必须要向图中提供一次输入数据。而Placeholder节点，正如其名，就是用来干这事的。在仿射变换计算图的例子中，$x$就是这种节点。</p><ul><li><strong>节点操作</strong>：无</li><li><strong>节点输入</strong>：无</li><li><strong>节点输出</strong>：<code>consumers</code>列表，它们将该节点的输出作为它们的输入。</li></ul><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>placeholder</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Represents a placeholder node that has to be provided with a value
</span></span></span><span class=line><span class=cl><span class=s2>       when computing the output of a computational graph
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>consumers</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>_default_graph</span><span class=o>.</span><span class=n>placeholders</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></div><h3 id=variables节点><a href=#variables节点 class=anchor-link><svg viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96.0-59.27-59.26-59.27-155.7.0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757.0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037.0 01-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482.0 0120.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96.0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454.0 0020.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037.0 00-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639.0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Variables节点</h3><p>在仿射变换的例子中，$x$,$A$和$b$都不是operation节点，但是$x$与$A$和$b$有一些区别，$x$是纯粹的输入placeholder节点，而$A$和$b$是能不断变更输出值，它们是Variable节点。这些Variable节点虽然没有输入，但本身有初值。Variable节点是计算图的固有成分。</p><ul><li><strong>节点操作</strong>：无</li><li><strong>节点输入</strong>：无</li><li><strong>节点输出</strong>：<code>consumers</code>列表，它们将该节点的输出作为它们的输入。</li></ul><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Variable</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Represents a variable (i.e. an intrinsic, changeable parameter of a computational graph).
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>initial_value</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>value</span> <span class=o>=</span> <span class=n>initial_value</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>consumers</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>_default_graph</span><span class=o>.</span><span class=n>variables</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></div><h3 id=the-graph-class><a href=#the-graph-class class=anchor-link><svg viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96.0-59.27-59.26-59.27-155.7.0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757.0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037.0 01-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482.0 0120.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96.0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454.0 0020.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037.0 00-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639.0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>The Graph class</h3><p>使用<code>Graph</code>来绑定所有创建的节点。当创建新的graph的时候，可以调用<code>as_default</code>方法来设置默认图<code>_default_graph</code>
，这样我们不用显示地去将节点绑定到图中。</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Graph</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;Construct Graph&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>operations</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>placeholders</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>variables</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>as_default</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>global</span> <span class=n>_default_graph</span>
</span></span><span class=line><span class=cl>        <span class=n>_default_graph</span> <span class=o>=</span> <span class=bp>self</span>
</span></span></code></pre></td></tr></table></div></div></div><h3 id=example><a href=#example class=anchor-link><svg viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96.0-59.27-59.26-59.27-155.7.0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757.0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037.0 01-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482.0 0120.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96.0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454.0 0020.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037.0 00-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639.0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Example</h3><p>通过已经建立的类，来建立仿射变换例子的计算图：</p><p>$$
z = \begin{pmatrix}
1 & 0 \\
0 & -1
\end{pmatrix}
\cdot
x</p><ul><li></li></ul><p>\begin{pmatrix}
1 \\
1
\end{pmatrix}
$$</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Create a new graph</span>
</span></span><span class=line><span class=cl><span class=n>Graph</span><span class=p>()</span><span class=o>.</span><span class=n>as_default</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create variables</span>
</span></span><span class=line><span class=cl><span class=n>A</span> <span class=o>=</span> <span class=n>Variable</span><span class=p>([[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]])</span>
</span></span><span class=line><span class=cl><span class=n>b</span> <span class=o>=</span> <span class=n>Variable</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create placeholder</span>
</span></span><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>placeholder</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create hidden node y</span>
</span></span><span class=line><span class=cl><span class=n>y</span> <span class=o>=</span> <span class=n>matmul</span><span class=p>(</span><span class=n>A</span><span class=p>,</span> <span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create output node z</span>
</span></span><span class=line><span class=cl><span class=n>z</span> <span class=o>=</span> <span class=n>add</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></div><h3 id=session><a href=#session class=anchor-link><svg viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96.0-59.27-59.26-59.27-155.7.0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757.0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037.0 01-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482.0 0120.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96.0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454.0 0020.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037.0 00-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639.0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Session</h3><p>建立完计算图，那么开始思考，如何计算出节点的输出？输出节点通常是operation节点。为了正确计算输出节点的输出，需要按正确的顺序计算。仍以仿射变换为例，要计算$z$必须先计算出中间结果$y$。也就是说，
<strong>必须保证节点是按顺序执行的，计算节点$o$之前，节点$o$的所有输入节点已经完成计算</strong>，使用<strong>拓扑排序</strong>即可满足要求。</p><p>拓扑排序，是原图的reverse post order，和反图的post order一致。这里使用反图的post order来得到拓扑顺序。这一系列计算都封装在了Session中。</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Session</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Represents a particular execution of a computational graph.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>run</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>operation</span><span class=p>,</span> <span class=n>feed_dict</span><span class=o>=</span><span class=p>{}):</span>
</span></span><span class=line><span class=cl>        <span class=n>nodes_postorder</span> <span class=o>=</span> <span class=n>traverse_postorder</span><span class=p>(</span><span class=n>operation</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># Iterate all nodes to determine their value</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>node</span> <span class=ow>in</span> <span class=n>nodes_postorder</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>type</span><span class=p>(</span><span class=n>node</span><span class=p>)</span> <span class=o>==</span> <span class=n>placeholder</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=c1># Set the node value to the placeholder value from feed_dict</span>
</span></span><span class=line><span class=cl>                <span class=n>node</span><span class=o>.</span><span class=n>output</span> <span class=o>=</span> <span class=n>feed_dict</span><span class=p>[</span><span class=n>node</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=k>elif</span> <span class=nb>type</span><span class=p>(</span><span class=n>node</span><span class=p>)</span> <span class=o>==</span> <span class=n>Variable</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=c1># Set the node value to the variable&#39;s value attribute</span>
</span></span><span class=line><span class=cl>                <span class=n>node</span><span class=o>.</span><span class=n>output</span> <span class=o>=</span> <span class=n>node</span><span class=o>.</span><span class=n>value</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>  <span class=c1># Operation</span>
</span></span><span class=line><span class=cl>                <span class=c1># Get the input values for this operation from node_values</span>
</span></span><span class=line><span class=cl>                <span class=n>node</span><span class=o>.</span><span class=n>inputs</span> <span class=o>=</span> <span class=p>[</span><span class=n>input_node</span><span class=o>.</span><span class=n>output</span> <span class=k>for</span> <span class=n>input_node</span> <span class=ow>in</span> <span class=n>node</span><span class=o>.</span><span class=n>input_nodes</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=c1># Compute the output of this operation</span>
</span></span><span class=line><span class=cl>                <span class=n>node</span><span class=o>.</span><span class=n>output</span> <span class=o>=</span> <span class=n>node</span><span class=o>.</span><span class=n>compute</span><span class=p>(</span><span class=o>*</span><span class=n>node</span><span class=o>.</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Convert lists to numpy arrays</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>type</span><span class=p>(</span><span class=n>node</span><span class=o>.</span><span class=n>output</span><span class=p>)</span> <span class=o>==</span> <span class=nb>list</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>node</span><span class=o>.</span><span class=n>output</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>node</span><span class=o>.</span><span class=n>output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># Return the requested node value</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>operation</span><span class=o>.</span><span class=n>output</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>traverse_postorder</span><span class=p>(</span><span class=n>operation</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>nodes_postorder</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>recurse</span><span class=p>(</span><span class=n>node</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>node</span><span class=p>,</span> <span class=n>Operation</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>input_node</span> <span class=ow>in</span> <span class=n>node</span><span class=o>.</span><span class=n>input_nodes</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>recurse</span><span class=p>(</span><span class=n>input_node</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>nodes_postorder</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>node</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>recurse</span><span class=p>(</span><span class=n>operation</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>nodes_postorder</span>
</span></span></code></pre></td></tr></table></div></div></div><p>可见，<code>run</code>方法对要计算的operation节点进行了一次拓扑排序，按照这个顺序，依次计算节点。</p><h4 id=example-1><a href=#example-1 class=anchor-link><svg viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96.0-59.27-59.26-59.27-155.7.0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757.0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037.0 01-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482.0 0120.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96.0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454.0 0020.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037.0 00-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639.0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>Example</h4><p>完成仿射变换例子的输出.</p><p>$$
z=\begin{pmatrix}1 & 0 \\ 0 & -1 \end{pmatrix} \cdot \begin{pmatrix}1 \\ 2\end{pmatrix} + \begin{pmatrix}
1 \\
1
\end{pmatrix}=
\begin{pmatrix}
2 \\
-1
\end{pmatrix}
$$</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>session</span> <span class=o>=</span> <span class=n>Session</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>session</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>z</span><span class=p>,</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>})</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>output</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></div><pre><code>[ 2 -1]
</code></pre><h2 id=小结><a href=#小结 class=anchor-link><svg viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96.0-59.27-59.26-59.27-155.7.0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757.0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037.0 01-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482.0 0120.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96.0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454.0 0020.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037.0 00-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639.0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a>小结</h2><p>目前，已经可以搭建计算图，用来计算一些复杂函数了。如果用计算图来搭建神经网络，目前的代码完全能够完成网络的前向传播。<a href=https://yinyajun.github.io/infomation-tech/tensorslow-02/ target=_blank rel=noopener>下篇</a>
将会涉及到loss计算及反向传播在计算图中如何实现。</p></div></article><div class=post-gitinfo><div class=post-gitinfo-left><div class="gitinfo-item commit"><a href=https://github.com/yinyajun/yinyajun.github.io/commit/6b43e86c001de2478814526692d500128ff59a88 target=_blank rel=noopener><svg viewBox="0 0 384 512" class="icon git-icon"><path d="M384 144c0-44.2-35.8-80-80-80s-80 35.8-80 80c0 36.4 24.3 67.1 57.5 76.8-.6 16.1-4.2 28.5-11 36.9-15.4 19.2-49.3 22.4-85.2 25.7-28.2 2.6-57.4 5.4-81.3 16.9v-144c32.5-10.2 56-40.5 56-76.3.0-44.2-35.8-80-80-80S0 35.8.0 80c0 35.8 23.5 66.1 56 76.3v199.3C23.5 365.9.0 396.2.0 432c0 44.2 35.8 80 80 80s80-35.8 80-80c0-34-21.2-63.1-51.2-74.6 3.1-5.2 7.8-9.8 14.9-13.4 16.2-8.2 40.4-10.4 66.1-12.8 42.2-3.9 90-8.4 118.2-43.4 14-17.4 21.1-39.8 21.6-67.9 31.6-10.8 54.4-40.7 54.4-75.9zM80 64c8.8.0 16 7.2 16 16s-7.2 16-16 16-16-7.2-16-16 7.2-16 16-16zm0 384c-8.8.0-16-7.2-16-16s7.2-16 16-16 16 7.2 16 16-7.2 16-16 16zm224-320c8.8.0 16 7.2 16 16s-7.2 16-16 16-16-7.2-16-16 7.2-16 16-16z"/></svg>6b43e86</a></div></div><div class=post-gitinfo-right><div class="gitinfo-item feedback"><a href=https://github.com/yinyajun/yinyajun.github.io/issues target=_blank rel=noopener><svg viewBox="0 0 384 512" class="icon feedback-icon"><path d="M202.021.0C122.202.0 70.503 32.703 29.914 91.026c-7.363 10.58-5.093 25.086 5.178 32.874l43.138 32.709c10.373 7.865 25.132 6.026 33.253-4.148 25.049-31.381 43.63-49.449 82.757-49.449 30.764.0 68.816 19.799 68.816 49.631.0 22.552-18.617 34.134-48.993 51.164-35.423 19.86-82.299 44.576-82.299 106.405V320c0 13.255 10.745 24 24 24h72.471c13.255.0 24-10.745 24-24v-5.773c0-42.86 125.268-44.645 125.268-160.627C377.504 66.256 286.902.0 202.021.0zM192 373.459c-38.196.0-69.271 31.075-69.271 69.271.0 38.195 31.075 69.27 69.271 69.27s69.271-31.075 69.271-69.271-31.075-69.27-69.271-69.27z"/></svg>反馈</a></div><div class="gitinfo-item edit"><a href=https://github.com/yinyajun/yinyajun.github.io/tree/main/content/posts/ai/tensorslow01.md target=_blank rel=noopener><svg viewBox="0 0 576 512" class="icon edit-icon"><path d="M402.3 344.9l32-32c5-5 13.7-1.5 13.7 5.7V464c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h273.5c7.1.0 10.7 8.6 5.7 13.7l-32 32c-1.5 1.5-3.5 2.3-5.7 2.3H48v352h352V350.5c0-2.1.8-4.1 2.3-5.6zm156.6-201.8L296.3 405.7l-90.4 10c-26.2 2.9-48.5-19.2-45.6-45.6l10-90.4L432.9 17.1c22.9-22.9 59.9-22.9 82.7.0l43.2 43.2c22.9 22.9 22.9 60 .1 82.8zM460.1 174 402 115.9 216.2 301.8l-7.3 65.3 65.3-7.3L460.1 174zm64.8-79.7-43.2-43.2c-4.1-4.1-10.8-4.1-14.8.0L436 82l58.1 58.1 30.9-30.9c4-4.2 4-10.8-.1-14.9z"/></svg>编辑</a></div></div></div><div class=related-posts><h2 class=related-title>相关文章：</h2><ul class=related-list><li class=related-item><a href=/posts/ai/tensorslow02/ class=related-link>有趣的TensorSlow(下)</a></li></ul></div><footer class=minimal-footer><div class=post-tag><a href=/tags/tensorslow/ rel=tag class=post-tag-link>#tensorslow</a></div><div class=post-category><a href=/categories/ai/ class=post-category-link>ai</a></div></footer></div></main><div id=back-to-top class=back-to-top><a href=#><svg viewBox="0 0 448 512" class="icon arrow-up"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6.0-33.9L207 39c9.4-9.4 24.6-9.4 33.9.0l194.3 194.3c9.4 9.4 9.4 24.6.0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3.0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg></a></div></div><script>"serviceWorker"in navigator&&window.addEventListener("load",function(){navigator.serviceWorker.register("/sw.js")})</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.css><script>if(typeof renderMathInElement=="undefined"){const e=e=>{const t=document.createElement("script");t.defer=!0,t.crossOrigin="anonymous",Object.keys(e).forEach(n=>{t[n]=e[n]}),document.body.appendChild(t)};e({src:"https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/katex.min.js",onload:()=>{e({src:"https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/mhchem.min.js",onload:()=>{e({src:"https://cdn.jsdelivr.net/npm/katex@0.13.0/dist/contrib/auto-render.min.js",onload:()=>{renderKaTex()}})}})}})}else renderKaTex();function renderKaTex(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})}</script></body></html>